{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.1.1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from qulacs import Observable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scikit_quri.circuit.pre_defined import create_dqn_cl, create_dqn_cl_no_cz\n",
    "from scikit_quri.circuit import LearningCircuit\n",
    "from scikit_quri.qnn.classifier import QNNClassifier\n",
    "from quri_parts.core.estimator.gradient import (\n",
    "    create_numerical_gradient_estimator,\n",
    "    create_parameter_shift_gradient_estimator)\n",
    "from quri_parts.qulacs.estimator import (\n",
    "    create_qulacs_vector_concurrent_estimator,\n",
    "    create_qulacs_vector_concurrent_parametric_estimator,\n",
    ")\n",
    "from quri_parts.algo.optimizer import Adam\n",
    "from quri_parts.core.operator import Operator, pauli_label\n",
    "# from scikit_quri.qnn.solver import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use wine dataset retrieved from: https://archive-beta.ics.uci.edu/ml/datasets/wine\n",
    "def load_dataset(\n",
    "    file_path: str, ignore_kind: int, test_ratio: float\n",
    ") -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "    \"\"\"Load dataset from specified path.\n",
    "\n",
    "    Args:\n",
    "        file_path: File path from which data is loaded.\n",
    "        ignore_kind: The dataset expected to have 3 classes and we need 2 classes to test. So specify here which class to ignore in loading.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(file_path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            kind = int(row[0])\n",
    "            if kind == ignore_kind:\n",
    "                continue\n",
    "            y.append(kind)\n",
    "            x.append([float(feature) for feature in row[1:]])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=test_ratio, shuffle=True\n",
    "    )\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(n_features: int, circuit:LearningCircuit, locality:int):\n",
    "    adam = Adam()\n",
    "    estimator = create_qulacs_vector_concurrent_estimator()\n",
    "    gradient_estimator = create_numerical_gradient_estimator(create_qulacs_vector_concurrent_parametric_estimator(),delta=1e-3)\n",
    "    ops = []\n",
    "    for i in range(n_features):\n",
    "        if i < locality:\n",
    "            op = Operator({pauli_label(f\"Z {i}\"):1.0})\n",
    "        # else:\n",
    "        #     op = Operator({pauli_label(f\"I {i}\"):1.0}) \n",
    "        ops.append(op)\n",
    "    classifier = QNNClassifier(circuit,2,estimator,gradient_estimator,optimizer=adam,operator=ops)\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.5693713925972863raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:1/5 cost:optimizer_state.cost=0.5136029575277631raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:2/5 cost:optimizer_state.cost=0.46514333707490146raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:3/5 cost:optimizer_state.cost=0.42709378984117014raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:4/5 cost:optimizer_state.cost=0.39904868070461863\n",
      "iteration:5 score:0.13846153846153847\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.3648770654263294raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:1/5 cost:optimizer_state.cost=0.33475118502246415raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:2/5 cost:optimizer_state.cost=0.30869220099181327raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:3/5 cost:optimizer_state.cost=0.2860706726736571raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:4/5 cost:optimizer_state.cost=0.2668357479426411\n",
      "iteration:10 score:0.7090909090909091\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.24760808342833274raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:1/5 cost:optimizer_state.cost=0.23090476722804237raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:2/5 cost:optimizer_state.cost=0.2187891681505057raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:3/5 cost:optimizer_state.cost=0.210406064176012raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:4/5 cost:optimizer_state.cost=0.2029534003699273\n",
      "iteration:15 score:0.7090909090909091\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.1918868163598873raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:1/5 cost:optimizer_state.cost=0.18068940457298982raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:2/5 cost:optimizer_state.cost=0.1693395762134628raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:3/5 cost:optimizer_state.cost=0.15920082698244237raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:4/5 cost:optimizer_state.cost=0.14972432582571293\n",
      "iteration:20 score:0.8083333333333333\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.14478521099095304raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:1/5 cost:optimizer_state.cost=0.13601968240875423raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:2/5 cost:optimizer_state.cost=0.13058467994483225raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:3/5 cost:optimizer_state.cost=0.12852421843395162raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:4/5 cost:optimizer_state.cost=0.1262713062382164\n",
      "iteration:25 score:1.0\n",
      "raw_grads.shape=(10, 13, 208)\n",
      "grads.shape=(208,)\n",
      " iter:0/5 cost:optimizer_state.cost=0.12589667371200622"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_dataset(\"../datasets/wine.data\", 3, 0.5)\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] -= 1\n",
    "for i in range(len(y_test)):\n",
    "    y_test[i] -= 1\n",
    "from icecream import ic\n",
    "\n",
    "n_features = 13\n",
    "locality = 2\n",
    "maxiter = 5\n",
    "\n",
    "n_train = 10\n",
    "n_test = 10\n",
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "x_test = x_test[:n_test]\n",
    "y_test = y_test[:n_test]\n",
    "import cProfile\n",
    "profiler = cProfile.Profile()\n",
    "print(\"CL\")\n",
    "circuit = create_dqn_cl(n_features, 5, locality)\n",
    "classifier = create_classifier(n_features,circuit,locality)\n",
    "result_cl = []\n",
    "loop_size = 80\n",
    "for i in range(loop_size):\n",
    "    classifier.fit(np.array(x_train), np.array(y_train), maxiter)\n",
    "    y_pred = classifier.predict(np.array(x_test)).argmax(axis=1)\n",
    "    score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    result_cl.append(score)\n",
    "    print(f\"iteration:{(i+1)*maxiter} score:{score}\")\n",
    "\n",
    "print(\"no CL\")\n",
    "circuit = create_dqn_cl_no_cz(n_features, 5)\n",
    "classifier = create_classifier(n_features,circuit, locality)\n",
    "result_no_cl = []\n",
    "for i in range(loop_size):\n",
    "    classifier.fit(np.array(x_train),np.array(y_train), maxiter)\n",
    "    y_pred = classifier.predict(np.array(x_test)).argmax(axis=1)\n",
    "    score = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    result_no_cl.append(score)\n",
    "    print(f\"iteration:{(i+1)*maxiter} score:{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(0, loop_size*maxiter, step=maxiter), np.array(result_cl).flatten(), label=\"CL\")\n",
    "plt.plot(np.arange(0, loop_size*maxiter, step=maxiter), np.array(result_no_cl).flatten(), label=\"no CL\")\n",
    "plt.xticks(np.arange(0, loop_size*maxiter, step=25))\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
